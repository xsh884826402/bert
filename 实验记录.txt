
2019年12月14日实验1：
    使用Large模型，squad1进行实验
    超参数：
        export BERT_BASE_DIR=~/User/xsh/bert_model/wwm_uncased_L-24_H-1024_A-16
        CUDA_VISIBLE_DEVICES=1 python run_squad.py --vocab_file=$BERT_BASE_DIR/vocab.txt --train_batch_size=8 --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --do_train=True --train_file=$SQUAD_DIR/train-v1.1.json --do_predict=True --predict_file=$SQUAD_DIR/dev-v1.1.json --learning_rate=3e-5 --max_seq_length=128 --doc_stride=128 --output_dir=$OUTPUT_DIR/squad1/wwm_uncased/
    实验结果：
        {"exact_match": 84.45600756859035, "f1": 91.14330997009772}

2019年12月14日实验2：
    使用base模型，squad1进行实验
    超参数：

            CUDA_VISIBLE_DEVICES=0 python run_squad.py \
            --vocab_file=$BERT_BASE_DIR/vocab.txt \
            --train_batch_size=8 \
            --bert_config_file=$BERT_BASE_DIR/bert_config.json \
            --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
            --do_train=True \
            --train_file=$SQUAD_DIR/train-v1.1.json \
            --do_predict=True \
            --predict_file=$SQUAD_DIR/dev-v1.1.json \
            --learning_rate=3e-5 \
            --max_seq_length=128 \
            --doc_stride=128 \
            --output_dir=$OUTPUT_DIR/squad1/uncased/
    实验结果：
            {"exact_match": 79.62157048249763, "f1": 87.07304907768032}

2019年12月14日实验3：
 可以看出使用base模型，squad2进行训练进行训练
 超参数：python run_squad.py --vocab_file=$BERT_BASE_DIR/vocab.txt --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --do_train=True --train_file=$SQUAD_DIR/train-v2.0.json --do_predict=True --predict_file=$SQUAD_DIR/dev-v2.0.json --train_batch_size=8 --learning_rate=3e-5 --num_train_epochs=3 --max_seq_length=128 --doc_stride=128 --output_dir=$OUTPUT_DIR/squad2-model/uncased_bert_base/ --version_2_with_negative=True --do_lower_case=True
 实验结果： {    "exact": 71.49835761812515,
                  "f1": 74.50810065472326,
                    "total": 11873,
                    "HasAns_exact": 66.16059379217273,
                    "HasAns_f1": 72.18871104479211,
                  "HasAns_total": 5928,
                  "NoAns_exact": 76.82085786375106,
                  "NoAns_f1": 76.82085786375106,
                  "NoAns_total": 5945
              }

2019年12月14日实验4：
    使用Large模型，squad2 进行实验
    超参数：
            CUDA_VISIBLE_DEVICES=1 python run_squad.py \
            --vocab_file=$BERT_BASE_DIR/vocab.txt \
            --bert_config_file=$BERT_BASE_DIR/bert_config.json \
            --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
            --do_train=True \
            --train_file=$SQUAD_DIR/train-v2.0.json \
            --do_predict=True \
            --predict_file=$SQUAD_DIR/dev-v2.0.json \
            --train_batch_size=8 \
            --learning_rate=3e-5 \
            --num_train_epochs=3 \
            --max_seq_length=128 \
            --doc_stride=128 \
            --output_dir=$OUTPUT_DIR/squad2-model/wwm_uncased_bert/ \
            --version_2_with_negative=True \
            --do_lower_case=True
    实验结果：
            {
                  "exact": 79.05331424239871,
                  "f1": 81.6839735939401,
                  "total": 11873,
                  "HasAns_exact": 73.85290148448043,
                  "HasAns_f1": 79.12176425115562,
                  "HasAns_total": 5928,
                  "NoAns_exact": 84.23885618166527,
                  "NoAns_f1": 84.23885618166527,
                  "NoAns_total": 5945
           }


-----------------------------------------------------2019-12-20日实验-----------------------------------
--------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------

探究新的分词方法，是否能对效果进行提升
实验一：
    使用base模型，squad1进行实验，使用bpe，并改变了WordPiece，
    新分词方法：
        ep: subsequence -> [subsequence,sub,sequence]

    超参数：
        使用改进的tokenization。
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12

        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_bpe/
    实验结果：
        {"exact_match": 78.9120151371807, "f1": 86.59188503936116}

实验二：
    使用base模型，squad1进行实验，
    WordPiece 分词，不返回原来的词,bpe_vocab_10000
     ep： subsequence -> [sub,sequence]
    超参数：
        252那台机器squ
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12

        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1220/
    实验结果：
        {"exact_match": 79.13907284768212, "f1": 86.60972084522086}
实验三：
    使用base模型，squad1进行实验
    超参数：
        不对bert进行改动
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12

        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1220/
    实验结果：
        {"exact_match": 79.51750236518448, "f1": 87.0505424483646}
分析发现 subsequence->[sub,sequence] 比[subsequence,sub,sequence]表现要好
-------------通过实验探究不同sequence的效果--------------------------
"""
实验四：
    使用base模型，squad1data进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=192 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1220_1/
    实验结果：
        {"exact_match": 80.72847682119205, "f1": 88.43634402562385}
实验五：
    使用base模型，squad1data进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=256 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1220_v2/
    实验结果：
        {"exact_match": 80.69063386944181, "f1": 88.17749931049202}
实验六：
    使用base模型，squad1data进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1220_3/
    实验结果：
        {"exact_match": 80.53926206244087, "f1": 88.29817709970612}

增长sequence确实能提高准确率，但是从192的长度之后对性能提升不够明显，192比128有明显提升，之后并没有了


"""
总结：
    应用bpe算法之后效果下降的原因，可能是以下几点：
    a.应用bpe算法之后vocab改动量不大，需要进行下一步的分析。bpe压缩的程度不同，使用10000，还是5000.
    b.fine_tune的训练比较少
    c.sequence_length的长度不够长，分别实验128,192,256,320
    d.不同任务会不会表现不同
    优先分析任务b，任务c。



-----------------------------------------------------2019-12-21日实验-----------------------------------
-------------通过实验探究不同epoches的效果--------------------------
实验一：
    使用base模型，squad1data进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_1/ \
        --num_train_epochs=5
    实验结果：
        {"exact_match": 78.6565752128666, "f1": 86.45842006868949}
实验三：
    使用base模型，squad1data进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_3/ \
        --num_train_epochs=7
    实验结果：
        {"exact_match": 78.38221381267739, "f1": 86.30651173974478}

实验二：
    使用base模型，squad1data进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_2/ \
        --num_train_epochs=9
    实验结果：
        {"exact_match": 77.32261116367077, "f1": 85.60257092352501}
总结：可以看出随着num_train_epoch的增长，整个效果是越来越差的。



---------------------------通过实验探究不同bpe_vocab对实验结果的影响-----------------------------
num_operation越高，对原始vocab的影响越小
10000 bpe_vocab
"exact_match": 79.13907284768212, "f1": 86.60972084522086}
（这个实验的第二次结果：可能做得有问题）
实验四：

    使用base模型 squad1,bpe_vocab_5000 operation
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_0/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 78.92147587511826, "f1": 86.47749841048096}

        {"exact_match": 79.29044465468307, "f1": 86.63610510042001}

        {"exact_match": 79.62157048249763, "f1": 86.88354086781754}
实验五：
    使用30000 的boe_vocab
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_1/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 78.86471144749291, "f1": 86.54765800618797}

        {"exact_match": 79.64049195837275, "f1": 87.06810481463847}

        {"exact_match": 79.3755912961211, "f1": 87.08034204440443}

实验六：
    使用50000 的boe_vocab
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=2 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_2/ \
        --num_train_epochs=3
        在252那台上用第一块卡uncased_1221_1
    实验结果：
        {"exact_match": 79.28098391674551, "f1": 86.78405224049017}

        {"exact_match": 79.56480605487228, "f1": 86.81720379046396}

        {"exact_match": 78.9593188268685, "f1": 86.50844912353614}


-----------------------------------------------2019年12月22日实验-------------------------------------------
-------------------------------使用bpe__vocab__50000,探究不同的sequence长度对实验结果的影响-----------------------------------------
实验七：
    使用50000 的bpe_vocab，sequence192
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=192 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_3/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 80.71901608325449, "f1": 88.09375792835857}

实验八：

    使用50000 的bpe_vocab，sequence256
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=256 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_4/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 80.74739829706716, "f1": 88.45606871337031}
实验九：
    使用50000 的bpe_vocab，sequence320
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=2 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1221_5/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 80.89877010406812, "f1": 88.43355830701755}

---------------------------------------2019年12月22日------------------------------------
探究不同的num_train_epoch对实验效果的影响
实验一：
    使用epochs=6,base,squad1
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12

        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_0/ \
        --num_train_epochs=6
    实验结果：
    {"exact_match": 78.73226111636707, "f1": 86.60328673122191}

实验二：
    使用epochs = 9
    超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_1/ \
        --num_train_epochs=9
    实验结果：
    {"exact_match": 77.59697256385998, "f1": 85.74962105915876}
实验三：
    使用epochs = 12
    超参数：
        CUDA_VISIBLE_DEVICES=2 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_2/ \
        --num_train_epochs=12
    实验结果：
        {"exact_match": 76.86849574266793, "f1": 85.21881759307661}
总结 可以看出：
        随着模型的进一步训练，效果越来越差
-------------------------------------------------------------------------------------------------
探究不同的bpe_vocab size 对实验结果的影响（未经过lower）
实验一：
     252那台机器
     应用bpe算法时候未经lower；使用bert推荐的sequence=384；，使用bpe_vocab=5000
     超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=384 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_0/ \
        --num_train_epochs=6
     实验结果：
        75.48 84.47
实验二:
     未经lower，使用boe——vocab = 30000
     超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=384 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_1/ \
        --num_train_epochs=6
     实验结果：
        78.74 87.09
     bpe——vocab 30000 的效果更好
------------------------------------------------------------------
探究不同的bpe-vocab 对实验结果的影响（应用bpe算法时对语料进行小写处理）
163那台机器
实验一：
    bpe经过lower；使用vocab——size = 5000
    超参数：
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_0/ \
        --num_train_epochs=6
    实验结果：
    73.96 83.25
实验二：
    使用lower，vocab_size 30000
    超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_1/ \
        --num_train_epochs=6
    实验结果：
        78.30 86.59
    未经lower的处理更好
-----------------------------------------------------------------
探究两种不同的tokenizationXSH对实验结果的影响
实验一：
    使用5000的bpe_vocab，利用AB->[A,B]
    超参数：
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_0/ \
        --num_train_epochs=6
    实验结果：

实验二：
    使用5000的bpe_vocab,利用AB->[AB,A,B]
    超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1222_1/ \
        --num_train_epochs=6
    实验结果：

-------------------------------------12-31日通过实验探究引入子词信息是否能提高实验效果---------------
实验一：
    使用原始的bert模型，探究实验效果
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1231-0/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 80.74739829706716, "f1": 88.26587179069762}
实验二：
    引入sub_word ,探究实验效果
    超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=320 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_1231-1/ \
        --num_train_epochs=3
    实验结果：
        {"exact_match": 80.37842951750237, "f1": 88.18473935156493}
------------------------------------一月一号 补充实验-------------------------
实验一：
    使用原始的bert模型，跑在squad2数据集上探究实验效果
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_0/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 71.23726101238103,
          "f1": 74.03737831744361,
          "total": 11873,
          "HasAns_exact": 67.20647773279352,
          "HasAns_f1": 72.81474236892822,
          "HasAns_total": 5928,
          "NoAns_exact": 75.2565180824222,
          "NoAns_f1": 75.2565180824222,
          "NoAns_total": 5945
        }


实验二：
    引入sub_word ,探究实验效果
    超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_1/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 72.87964288722311,
          "f1": 75.82408601805253,
          "total": 11873,
          "HasAns_exact": 67.05465587044534,
          "HasAns_f1": 72.95198604796494,
          "HasAns_total": 5928,
          "NoAns_exact": 78.68797308662742,
          "NoAns_f1": 78.68797308662742,
          "NoAns_total": 5945
        }
补充实验，确认验证实验效果
实验三：
    使用原始的bert模型，跑在squad2数据集上探究实验效果
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_2/ \
        --version_2_with_negative=True
    实验结果：
        {
              "exact": 72.93860018529436,
              "f1": 75.9107797579275,
              "total": 11873,
              "HasAns_exact": 66.0425101214575,
              "HasAns_f1": 71.99539272366266,
              "HasAns_total": 5928,
              "NoAns_exact": 79.81497056349873,
              "NoAns_f1": 79.81497056349873,
              "NoAns_total": 5945
            }

实验四：
    引入subword子词信息
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_3/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 71.29621831045229,
          "f1": 74.38637723913878,
          "total": 11873,
          "HasAns_exact": 66.16059379217273,
          "HasAns_f1": 72.34977344134496,
          "HasAns_total": 5928,
          "NoAns_exact": 76.41715727502103,
          "NoAns_f1": 76.41715727502103,
          "NoAns_total": 5945
        }
实验五：
    使用原始的bert模型，跑在squad2数据集上探究实验效果
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_4/ \
        --version_2_with_negative=True
    实验结果：
                {
          "exact": 73.12389455066116,
          "f1": 76.06757207850616,
          "total": 11873,
          "HasAns_exact": 67.24021592442645,
          "HasAns_f1": 73.13601270042227,
          "HasAns_total": 5928,
          "NoAns_exact": 78.99074852817493,
          "NoAns_f1": 78.99074852817493,
          "NoAns_total": 5945
        }

实验6：
    引入subword，squad2上进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_5/ \
        --version_2_with_negative=True
    实验结果：
                    {
              "exact": 72.45009685841826,
              "f1": 75.23613106213675,
              "total": 11873,
              "HasAns_exact": 66.8859649122807,
              "HasAns_f1": 72.46602295896558,
              "HasAns_total": 5928,
              "NoAns_exact": 77.99831791421363,
              "NoAns_f1": 77.99831791421363,
              "NoAns_total": 5945
            }

实验七：
    使用subword，,并观察最后是否输出print不进行init
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=2 python run_squad.py \
        --vocab_file=/home/ubuntu/User/xsh/bert_model/xsh/vocab.txt \
        --bert_config_file=/home/ubuntu/User/xsh/bert_model/xsh/bert_config.json \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_6/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 49.4904404952413,
          "f1": 49.58718561229402,
          "total": 11873,
          "HasAns_exact": 0.47233468286099867,
          "HasAns_f1": 0.6661023574168066,
          "HasAns_total": 5928,
          "NoAns_exact": 98.36837678721615,
          "NoAns_f1": 98.36837678721615,
          "NoAns_total": 5945
        }
实验八：
    不使用subword，,并观察最后是否输出print不进行init
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=2 python run_squad.py \
        --vocab_file=/home/ubuntu/User/xsh/bert_model/xsh/vocab.txt \
        --bert_config_file=/home/ubuntu/User/xsh/bert_model/xsh/bert_config.json \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_7/ \
        --version_2_with_negative=True
    实验结果：
           {
          "exact": 49.56624273561863,
          "f1": 49.6728567835583,
          "total": 11873,
          "HasAns_exact": 0.37112010796221323,
          "HasAns_f1": 0.5846539458818583,
          "HasAns_total": 5928,
          "NoAns_exact": 98.62068965517241,
          "NoAns_f1": 98.62068965517241,
          "NoAns_total": 5945
        }




----------------------------------10.1.114.118那台机器-----------------------
10.1.114.118那一台机器
实验1:
    引入subword信息，探究实验结果
    超参数：
        export SQUAD_DIR=~/User/xsh/squad1_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/xsh
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_11_0/ \
        --num_train_epochs=5
    实验结果：
实验二：
    原始的bert改进的模型，不引入subword
    超参数：
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --train_batch_size=8 \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v1.1.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v1.1.json \
        --learning_rate=3e-5 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad1/uncased_11_1/ \
        --num_train_epochs=5
    实验结果：

实验三：
    原始的bert模型在squad2上的结果；机器118
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_2/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 72.34060473342879,
          "f1": 75.32214031787335,
          "total": 11873,
          "HasAns_exact": 66.2280701754386,
          "HasAns_f1": 72.19969163193475,
          "HasAns_total": 5928,
          "NoAns_exact": 78.43566021867115,
          "NoAns_f1": 78.43566021867115,
          "NoAns_total": 5945
        }

实验四：
    引入subword信息，在squad2数据集上进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_3/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 72.99755748336563,
          "f1": 75.87539722571249,
          "total": 11873,
          "HasAns_exact": 67.76315789473684,
          "HasAns_f1": 73.52709029367121,
          "HasAns_total": 5928,
          "NoAns_exact": 78.2169890664424,
          "NoAns_f1": 78.2169890664424,
          "NoAns_total": 5945
        }

实验五：
    使用原始的bert模型，跑在squad2数据集上探究实验效果
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_4/ \
        --version_2_with_negative=True
    实验结果：
                {
          "exact": 72.50905415648951,
          "f1": 75.57206851115782,
          "total": 11873,
          "HasAns_exact": 66.86909581646424,
          "HasAns_f1": 73.0039084738488,
          "HasAns_total": 5928,
          "NoAns_exact": 78.13288477712364,
          "NoAns_f1": 78.13288477712364,
          "NoAns_total": 5945
        }



实验6：
    引入subword，squad2上进行实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_11_5/ \
        --version_2_with_negative=True
    实验结果：
        {
          "exact": 71.94474858923608,
          "f1": 74.92002081694834,
          "total": 11873,
          "HasAns_exact": 66.56545209176788,
          "HasAns_f1": 72.52452887308142,
          "HasAns_total": 5928,
          "NoAns_exact": 77.30866274179984,
          "NoAns_f1": 77.30866274179984,
          "NoAns_total": 5945
        }
-------------------------------------2020年一月2号------------------------------------
119那台机器
实验一：
    使用原始的bert模型，在squad2上进行实验，换卡跑实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_12_1/ \
        --version_2_with_negative=True
    实验结果：

实验二：
    使用subword，在suqad2实验，与之前所用的卡不同
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_12_0/ \
        --version_2_with_negative=True
     实验结果：
--------------------------》》》》》》》》》》》》》
118那台机器
实验一：
    使用原始的bert模型，在squad2上进行实验，换卡跑实验
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=1 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_12_1/ \
        --version_2_with_negative=True
    实验结果：

实验二：
    使用subword，在suqad2实验，与之前所用的卡不同
    超参数：
        export SQUAD_DIR=~/User/xsh/squad2_data
        export OUTPUT_DIR=~/User/xsh/Model
        export BERT_BASE_DIR=~/User/xsh/bert_model/uncased_L-12_H-768_A-12
        CUDA_VISIBLE_DEVICES=0 python run_squad.py \
        --vocab_file=$BERT_BASE_DIR/vocab.txt \
        --bert_config_file=$BERT_BASE_DIR/bert_config.json \
        --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
        --do_train=True \
        --train_file=$SQUAD_DIR/train-v2.0.json \
        --do_predict=True \
        --predict_file=$SQUAD_DIR/dev-v2.0.json \
        --train_batch_size=8 \
        --learning_rate=3e-5 \
        --num_train_epochs=3 \
        --max_seq_length=128 \
        --doc_stride=128 \
        --output_dir=$OUTPUT_DIR/squad2-model/uncased_12_0/ \
        --version_2_with_negative=True
     实验结果：
















